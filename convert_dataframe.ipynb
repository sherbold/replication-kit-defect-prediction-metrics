{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv==0.19.2 in c:\\users\\steffen\\anaconda3\\envs\\thesis\\lib\\site-packages (0.19.2)\n",
      "Requirement already satisfied: PyMySQL==1.0.2 in c:\\users\\steffen\\anaconda3\\envs\\thesis\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: numpy==1.20.2 in c:\\users\\steffen\\anaconda3\\envs\\thesis\\lib\\site-packages (1.20.2)\n",
      "Requirement already satisfied: pandas==1.2.4 in c:\\users\\steffen\\anaconda3\\envs\\thesis\\lib\\site-packages (1.2.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\steffen\\anaconda3\\envs\\thesis\\lib\\site-packages (from pandas==1.2.4) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\steffen\\anaconda3\\envs\\thesis\\lib\\site-packages (from pandas==1.2.4) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\steffen\\anaconda3\\envs\\thesis\\lib\\site-packages (from python-dateutil>=2.7.3->pandas==1.2.4) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install python-dotenv==0.19.2 PyMySQL==1.0.2 numpy==1.20.2 pandas==1.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "\n",
    "pd.set_option('display.max_columns', 40)\n",
    "\n",
    "USE_DATABASE = False\n",
    "SQL_TABLENAME_BOOTSTRAP = \"results_rr\"\n",
    "SQL_TABLENAME_GENERALIZATION = \"generalization\"\n",
    "\n",
    "CSV_CROSSPARE_BOOTSTRAP = \"data/database_metrics_vs_costsaving_bt_exp.csv\"\n",
    "CSV_CROSSPARE_GENERALIZATION = \"data/database_metrics_vs_costsaving_real.csv\"\n",
    "\n",
    "CSV_OUTPUT_BOOTSTRAP = \"data/metrics_vs_costsaving_bootstrap_experiment.csv\"\n",
    "CSV_OUTPUT_GENERALIZATION = \"data/metrics_vs_costsaving_realistic_settings.csv\"\n",
    "\n",
    "if USE_DATABASE:\n",
    "    load_dotenv(\"db_credentials.env\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dataframe(mysql_df : pd.DataFrame):\n",
    "    \"\"\"Converts a dataframe from CrossPare's MySQL database format to make it fitting for the analysis.\n",
    "    \n",
    "    The conversion is done in multiple steps: First the columns getting renamed.\n",
    "    Afterwards the missing columns are computed. And finally the relevant columns are selected.\n",
    "    \n",
    "    Args:\n",
    "        mysql_df: original dataframe\n",
    "        \n",
    "    Returns:\n",
    "        pd.Dataframe: converted dataframe\n",
    "    \"\"\"\n",
    "    df = mysql_df.copy(deep=True)\n",
    "\n",
    "    # rename columns\n",
    "    df.rename(columns = {\n",
    "                     'fscore':'f_measure',\n",
    "                     'gscore':'g_measure',\n",
    "                     'aucAlberg':'auc_alberg',\n",
    "                     'aucRoI':'auc_roi',\n",
    "                     'nofi80':'nofc80',\n",
    "                     'biasTrainingOriginal':'bias_train',\n",
    "                     'biasTraining':'bias_train_processed',\n",
    "                     'biasTest':'bias_test',\n",
    "                     'prop1Defect':'prop1_defect',\n",
    "                     'prop1Clean':'prop1_clean',\n",
    "                     'trainsizeOriginal':'num_train',\n",
    "                     'trainsize':'num_train_processed',\n",
    "                     'testsize':'num_test'\n",
    "                        }, inplace = True)\n",
    "\n",
    "    # treat edge cases of existing variables\n",
    "    df.loc[ (df['tp']==0) & (df['fn']==0), 'recall' ] = 1 # The model predicted \"all\" of the none defective instances (1)\n",
    "    df.loc[ (df['tp']==0) & (df['fp']==0), 'precision'] = 1 # if nothing is predicted as defective, the precision is 1.\n",
    "    df['f_measure'] = np.where( ( df['recall'] + df['precision'] )!=0,\n",
    "                                2 * ( df['recall'] * df['precision'] ) / ( df['recall'] + df['precision'] ),\n",
    "                                0)\n",
    "    df['g_measure'] = np.where( ( df['recall'] + ( 1 - df['fpr'] ) )!=0,\n",
    "                                2 * ( df['recall'] * ( 1 - df['fpr'] ) ) / ( df['recall'] + ( 1 - df['fpr'] ) ),\n",
    "                                0)\n",
    "    df['balance'] = 1 - ( ( (1-df['recall'])**2 + df['fpr']**2 )**(1/2) / 2**(1/2) )\n",
    "    df['mcc'] = np.where( ( (df['tp']+df['fp'])*(df['tp']+df['fn'])*(df['tn']+df['fp'])*(df['tn']+df['fn']) )!=0,\n",
    "                          df['mcc'],\n",
    "                          0)\n",
    "    df.loc[ (df['tp']==0) & (df['fn']==0), 'auc' ] = np.nan\n",
    "    df.loc[ (df['tp']==0) & (df['fn']==0), 'auc_alberg' ] = np.nan\n",
    "    df.loc[ (df['tp']==0) & (df['fn']==0), 'auc_roi' ] = np.nan\n",
    "    df['nofc80'] = np.where( (df['tp']+df['fn'])!=0,\n",
    "                             df['nofc80'],\n",
    "                             np.nan)\n",
    "    df['prop1_defect'] = np.where( (df['tp']+df['fn'])!=0,\n",
    "                                   df['prop1_defect'],\n",
    "                                   np.nan)\n",
    "\n",
    "    # calculate missing variables\n",
    "    df[\"fpr\"] = df[\"fp\"] / (df[\"tn\"] + df[\"fp\"])\n",
    "    df[\"accuracy\"] = (df[\"tp\"] + df[\"tn\"]) / df[\"num_test\"]\n",
    "    df[\"error_type1\"] = np.where( ( df[\"tp\"] + df[\"fn\"] )!=0,\n",
    "                                  ( df[\"fp\"] / (df[\"tp\"] + df[\"fn\"]) ),\n",
    "                                  np.inf)\n",
    "    df[\"error_type2\"] = df[\"fn\"] / (df[\"tn\"] + df[\"fp\"])\n",
    "    df[\"consistency\"] = np.where( ( ( df[\"tp\"] + df[\"fn\"] ) * ( df[\"tn\"] + df[\"fp\"] ) )!=0,\n",
    "                                  ( ( df[\"tp\"] * df[\"num_test\"] ) - ( df[\"tp\"] + df[\"fn\"] )**2) / ( ( df[\"tp\"] + df[\"fn\"] ) * ( df[\"tn\"] + df[\"fp\"] ) ),\n",
    "                                  np.nan)\n",
    "    df[\"ratio_bias\"] = df[\"bias_test\"] / df[\"bias_train\"]\n",
    "    df[\"ratio_bias_processed\"] = np.where(df[\"bias_train_processed\"]!=0,\n",
    "                                          df[\"bias_test\"] / df[\"bias_train_processed\"],\n",
    "                                          np.nan)\n",
    "\n",
    "    # calculate diff value\n",
    "    df[\"diff\"] = df[\"upperSizeNtoM\"] - df[\"lowerSizeNtoM\"]\n",
    "    df['unregular_lower_bound'] = \"regular\"\n",
    "    df['unregular_upper_bound'] = \"regular\"\n",
    "    df.loc[(df['tp'] ==0) &  (df['fp'] !=0) , 'unregular_lower_bound'] = '+inf'\n",
    "    df.loc[(df['tp'] ==0) &  (df['fp'] ==0) , 'unregular_lower_bound'] = 'NaN'\n",
    "    df.loc[(df['fn'] ==0) &  (df['tn'] !=0) , 'unregular_upper_bound'] = '+inf'\n",
    "    df.loc[(df['fn'] ==0) &  (df['tn'] ==0) , 'unregular_upper_bound'] = 'NaN'\n",
    "    df.loc[(df['unregular_lower_bound'] =='NaN') |  (df['unregular_upper_bound'] =='Nan') , 'diff'] = np.nan\n",
    "    df.loc[(df['unregular_lower_bound'] =='+inf') &  (df['unregular_upper_bound'] =='+inf') , 'diff'] = np.nan\n",
    "    df.loc[(df['unregular_lower_bound'] =='+inf') &  (df['unregular_upper_bound'] =='regular') , 'diff'] = -np.inf\n",
    "    df.loc[(df['unregular_lower_bound'] =='regular') &  (df['unregular_upper_bound'] =='+inf') , 'diff'] = np.inf\n",
    "\n",
    "    # get cost saving potential classes\n",
    "    conditions = [\n",
    "        (df['diff'] <= 0) | (df['diff'] == -np.inf) | (df['diff'].isnull()),\n",
    "        (df['diff'] > 0) & (df['diff'] <= 10),\n",
    "        (df['diff'] > 10) & (df['diff'] <= 100),\n",
    "        (df['diff'] > 100) & (df['diff'] <= 1000),\n",
    "        (df['diff'] > 1000) & (df['diff'] <= 10000),\n",
    "        (df['diff'] > 10000 | (df['diff'] == np.inf))\n",
    "        ]\n",
    "    # create a list of the values we want to assign for each condition\n",
    "    potentials = ['none', 'negligible', 'small', 'medium', 'large', 'extra_large']\n",
    "    # create a new column and use np.select to assign values to it using our lists as arguments\n",
    "    df['potential'] = np.select(conditions, potentials)\n",
    "\n",
    "    # pick relevant columns\n",
    "    independent_variables = [\"recall\", \"precision\", \"fpr\", \"f_measure\", \"g_measure\", \"balance\", \"accuracy\",\n",
    "                         \"error\", \"error_type1\", \"error_type2\", \"mcc\", \"consistency\", \"auc\", \"auc_alberg\", \"auc_roi\",\n",
    "                         \"necm10\", \"necm25\", \"cost\", \"nofb20\", \"nofc80\"]\n",
    "    confounding_variables = [\"bias_train\", \"bias_train_processed\", \"bias_test\", \"ratio_bias\", \"ratio_bias_processed\",\n",
    "                             \"prop1_defect\", \"prop1_clean\", \"num_train\", \"num_train_processed\", \"num_test\"]\n",
    "    column_list = [\"configuration\"] + [\"release\"] + independent_variables + confounding_variables + [\"diff\"] + [\"potential\"]\n",
    "    df = df[column_list]\n",
    "    return df\n",
    "\n",
    "def few_descriptive_stats(df):\n",
    "    \"\"\"Returns a dataframe containing descriptive statistics for detecting invalid values.\"\"\"\n",
    "    desc_stats = pd.DataFrame(columns=df.columns)\n",
    "    desc_stats = desc_stats.append((df.mean(axis=0).rename(\"mean\")))\n",
    "    desc_stats = desc_stats.append((df.median(axis=0).rename(\"median\")))\n",
    "    desc_stats = desc_stats.append(df.min(axis=0, numeric_only=True).rename(\"min\"))\n",
    "    desc_stats = desc_stats.append(df.max(axis=0, numeric_only=True).rename(\"max\"))\n",
    "    return desc_stats\n",
    "\n",
    "def nan_and_inf_evaluation(df):\n",
    "    \"\"\"Prints information about the occurrences of NaN values in the dataset\"\"\"\n",
    "    print(f\"Overall number of NaN:               {df.isna().sum().sum()}\")\n",
    "    print(f\"Overall number of NaN (no 'diff'):   {df.drop('diff', axis=1).isna().sum().sum()}\")\n",
    "    print(f\"Number of rows with NaN:             {df[df.isna().any(axis=1)].shape[0]}\")\n",
    "    print(f\"Number of rows with NaN (no 'diff'): {df[df.drop('diff', axis=1).isna().any(axis=1)].shape[0]}\")\n",
    "    print(\"\\nNaNs per variable:\")\n",
    "    print(df.isna().sum().loc[df.isna().sum()>0] )\n",
    "    print(\"\\ninfs per variable:\")\n",
    "    inf_array = np.isinf(df.drop([\"configuration\",\"release\",\"potential\"], axis=1)).sum()\n",
    "    print(inf_array[inf_array>0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_DATABASE:\n",
    "    db_host = os.getenv('DB_HOST')\n",
    "    db_port = int(os.getenv('DB_PORT'))\n",
    "    db_user = os.getenv('DB_USER')\n",
    "    db_pass = os.getenv('DB_PASS')\n",
    "    db_name = os.getenv('DB_NAME')\n",
    "    dbcon = pymysql.connect(host=db_host, user=db_user, password=db_pass, database=db_name, port=db_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get bootstrap experiment data\n",
    "### Query bootstrap experiment dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of dataframe: (53000, 115)\n"
     ]
    },
    {
     "data": {
      "text/plain": "        configuration  release     idresults  configurationName  productName  \\\nmean              NaN      NaN  46019.841868                NaN          NaN   \nmedian            NaN      NaN  52424.000000                NaN          NaN   \nmin               NaN      NaN      1.000000                NaN          NaN   \nmax               NaN      NaN  79500.000000                NaN          NaN   \n\n        classifier    testsize    trainsize  trainsizeOriginal  biasTest  \\\nmean           NaN  186.097717   560.944302         506.490566  0.065939   \nmedian         NaN  153.000000   462.000000         425.000000  0.054348   \nmin            NaN   28.000000   100.000000         100.000000  0.002481   \nmax            NaN  667.000000  1940.000000        1708.000000  0.382353   \n\n        biasTraining  biasTrainingOriginal  prop1Defect  prop1Clean     error  \\\nmean        0.150173              0.065685   152.347081   15.084337  0.071236   \nmedian      0.108252              0.054417    83.400000   10.806122  0.059406   \nmin         0.002347              0.002347     5.600000    1.819095  0.000000   \nmax         0.692641              0.333333  3756.000000   92.700000  0.400000   \n\n          recall  precision    fscore    gscore       mcc  ...  \\\nmean    0.171032   0.066191 -0.034434  0.239728 -0.273583  ...   \nmedian  0.090909   0.250000  0.142857  0.166604  0.129023  ...   \nmin     0.000000  -1.000000 -1.000000  0.000000 -2.000000  ...   \nmax     1.000000   1.000000  1.000000  1.000000  1.000000  ...   \n\n        lowerConstNtoMImp40  upperConstNtoMImp40  lowerSize1to1Imp40  \\\nmean               0.329204            94.173707         1614.561656   \nmedian             0.211864            37.666667          439.226190   \nmin               -1.000000            -1.000000           -1.000000   \nmax               77.160494        338164.776026        65188.333333   \n\n        upperSize1to1Imp40  lowerSize1toMImp40  upperSize1toMImp40  \\\nmean           4994.255011         1220.851624         4382.491603   \nmedian         3325.555556          318.888889         2850.458333   \nmin              -1.000000           -1.000000           -1.000000   \nmax          120001.666667        65188.333333       120001.666667   \n\n        lowerSizeNtoMImp40  upperSizeNtoMImp40  lowerConst1to1Imp50  \\\nmean            188.967099        7.093923e+03             2.284447   \nmedian           82.994845        3.492925e+03             2.000000   \nmin              -1.000000       -1.000000e+00            -1.000000   \nmax           12297.222222        1.326499e+07            42.000000   \n\n        upperConst1to1Imp50  lowerConst1toMImp50  upperConst1toMImp50  \\\nmean              61.427844             1.702248            54.499107   \nmedian            42.857143             1.500000            37.000000   \nmin               -1.000000            -1.000000            -1.000000   \nmax              804.000000            42.000000           804.000000   \n\n        lowerConstNtoMImp50  upperConstNtoMImp50  lowerSize1to1Imp50  \\\nmean               0.361874         4.817570e+02         1937.563029   \nmedian             0.214286         4.586667e+01          527.071429   \nmin               -1.000000        -1.000000e+00           -1.000000   \nmax              192.000000         5.210112e+06        78226.000000   \n\n        upperSize1to1Imp50  lowerSize1toMImp50  upperSize1toMImp50  \\\nmean           5993.108213         1465.110990         5258.992124   \nmedian         3990.666667          382.666667         3420.550000   \nmin              -1.000000           -1.000000           -1.000000   \nmax          144002.000000        78226.000000       144002.000000   \n\n        lowerSizeNtoMImp50  upperSizeNtoMImp50  \nmean            194.965369        2.495201e+04  \nmedian           83.755000        4.249163e+03  \nmin              -1.000000       -1.000000e+00  \nmax           17708.000000        2.043740e+08  \n\n[4 rows x 117 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>configuration</th>\n      <th>release</th>\n      <th>idresults</th>\n      <th>configurationName</th>\n      <th>productName</th>\n      <th>classifier</th>\n      <th>testsize</th>\n      <th>trainsize</th>\n      <th>trainsizeOriginal</th>\n      <th>biasTest</th>\n      <th>biasTraining</th>\n      <th>biasTrainingOriginal</th>\n      <th>prop1Defect</th>\n      <th>prop1Clean</th>\n      <th>error</th>\n      <th>recall</th>\n      <th>precision</th>\n      <th>fscore</th>\n      <th>gscore</th>\n      <th>mcc</th>\n      <th>...</th>\n      <th>lowerConstNtoMImp40</th>\n      <th>upperConstNtoMImp40</th>\n      <th>lowerSize1to1Imp40</th>\n      <th>upperSize1to1Imp40</th>\n      <th>lowerSize1toMImp40</th>\n      <th>upperSize1toMImp40</th>\n      <th>lowerSizeNtoMImp40</th>\n      <th>upperSizeNtoMImp40</th>\n      <th>lowerConst1to1Imp50</th>\n      <th>upperConst1to1Imp50</th>\n      <th>lowerConst1toMImp50</th>\n      <th>upperConst1toMImp50</th>\n      <th>lowerConstNtoMImp50</th>\n      <th>upperConstNtoMImp50</th>\n      <th>lowerSize1to1Imp50</th>\n      <th>upperSize1to1Imp50</th>\n      <th>lowerSize1toMImp50</th>\n      <th>upperSize1toMImp50</th>\n      <th>lowerSizeNtoMImp50</th>\n      <th>upperSizeNtoMImp50</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>mean</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>46019.841868</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>186.097717</td>\n      <td>560.944302</td>\n      <td>506.490566</td>\n      <td>0.065939</td>\n      <td>0.150173</td>\n      <td>0.065685</td>\n      <td>152.347081</td>\n      <td>15.084337</td>\n      <td>0.071236</td>\n      <td>0.171032</td>\n      <td>0.066191</td>\n      <td>-0.034434</td>\n      <td>0.239728</td>\n      <td>-0.273583</td>\n      <td>...</td>\n      <td>0.329204</td>\n      <td>94.173707</td>\n      <td>1614.561656</td>\n      <td>4994.255011</td>\n      <td>1220.851624</td>\n      <td>4382.491603</td>\n      <td>188.967099</td>\n      <td>7.093923e+03</td>\n      <td>2.284447</td>\n      <td>61.427844</td>\n      <td>1.702248</td>\n      <td>54.499107</td>\n      <td>0.361874</td>\n      <td>4.817570e+02</td>\n      <td>1937.563029</td>\n      <td>5993.108213</td>\n      <td>1465.110990</td>\n      <td>5258.992124</td>\n      <td>194.965369</td>\n      <td>2.495201e+04</td>\n    </tr>\n    <tr>\n      <th>median</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>52424.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>153.000000</td>\n      <td>462.000000</td>\n      <td>425.000000</td>\n      <td>0.054348</td>\n      <td>0.108252</td>\n      <td>0.054417</td>\n      <td>83.400000</td>\n      <td>10.806122</td>\n      <td>0.059406</td>\n      <td>0.090909</td>\n      <td>0.250000</td>\n      <td>0.142857</td>\n      <td>0.166604</td>\n      <td>0.129023</td>\n      <td>...</td>\n      <td>0.211864</td>\n      <td>37.666667</td>\n      <td>439.226190</td>\n      <td>3325.555556</td>\n      <td>318.888889</td>\n      <td>2850.458333</td>\n      <td>82.994845</td>\n      <td>3.492925e+03</td>\n      <td>2.000000</td>\n      <td>42.857143</td>\n      <td>1.500000</td>\n      <td>37.000000</td>\n      <td>0.214286</td>\n      <td>4.586667e+01</td>\n      <td>527.071429</td>\n      <td>3990.666667</td>\n      <td>382.666667</td>\n      <td>3420.550000</td>\n      <td>83.755000</td>\n      <td>4.249163e+03</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>28.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>0.002481</td>\n      <td>0.002347</td>\n      <td>0.002347</td>\n      <td>5.600000</td>\n      <td>1.819095</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>-2.000000</td>\n      <td>...</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000e+00</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000e+00</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000e+00</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>79500.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>667.000000</td>\n      <td>1940.000000</td>\n      <td>1708.000000</td>\n      <td>0.382353</td>\n      <td>0.692641</td>\n      <td>0.333333</td>\n      <td>3756.000000</td>\n      <td>92.700000</td>\n      <td>0.400000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>77.160494</td>\n      <td>338164.776026</td>\n      <td>65188.333333</td>\n      <td>120001.666667</td>\n      <td>65188.333333</td>\n      <td>120001.666667</td>\n      <td>12297.222222</td>\n      <td>1.326499e+07</td>\n      <td>42.000000</td>\n      <td>804.000000</td>\n      <td>42.000000</td>\n      <td>804.000000</td>\n      <td>192.000000</td>\n      <td>5.210112e+06</td>\n      <td>78226.000000</td>\n      <td>144002.000000</td>\n      <td>78226.000000</td>\n      <td>144002.000000</td>\n      <td>17708.000000</td>\n      <td>2.043740e+08</td>\n    </tr>\n  </tbody>\n</table>\n<p>4 rows × 117 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if USE_DATABASE:\n",
    "    db_table = SQL_TABLENAME_BOOTSTRAP\n",
    "    bt_df = pd.read_sql_query(f\"SELECT * FROM {db_table} WHERE configurationName LIKE '%NoSmote%' OR configurationName LIKE '%Smotuned%'\", dbcon)\n",
    "\n",
    "    bt_df.to_csv(CSV_CROSSPARE_BOOTSTRAP, index=False)\n",
    "else:\n",
    "    bt_df = pd.read_csv(CSV_CROSSPARE_BOOTSTRAP,index_col=False)\n",
    "\n",
    "print(f\"shape of dataframe: {bt_df.shape}\")\n",
    "\n",
    "release_col = bt_df[\"productName\"].str.replace(\"_aggregated.csv\", \"\", regex=True)\n",
    "bt_df.insert(0, 'release', release_col)\n",
    "\n",
    "config_col = bt_df['configurationName'].apply(lambda x: 'Smotuned' if \"Smotuned\" in x else 'NoSmote')\n",
    "bt_df.insert(0, 'configuration', config_col)\n",
    "\n",
    "few_descriptive_stats(bt_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Convert bootstrap dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        configuration  release    recall  precision       fpr  f_measure  \\\nmean              NaN      NaN  0.171032   0.521851  0.022190   0.193396   \nmedian            NaN      NaN  0.090909   0.500000  0.010989   0.142857   \nmin               NaN      NaN  0.000000   0.000000  0.000000   0.000000   \nmax               NaN      NaN  1.000000   1.000000  0.404762   1.000000   \n\n        g_measure   balance  accuracy     error  error_type1  error_type2  \\\nmean     0.239728  0.412477  0.928764  0.071236     0.326751     0.056615   \nmedian   0.166604  0.357168  0.940594  0.059406     0.190476     0.047120   \nmin      0.000000  0.270018  0.600000  0.000000     0.000000     0.000000   \nmax      1.000000  1.000000  1.000000  0.400000    12.000000     0.476190   \n\n             mcc  consistency       auc  auc_alberg   auc_roi    necm10  \\\nmean    0.182078     0.114417  0.790624    0.013403  0.575275  0.532306   \nmedian  0.129023     0.015152  0.807238    0.006870  0.572759  0.461538   \nmin    -0.173902    -0.466667  0.055556    0.000000  0.012178  0.000000   \nmax     1.000000     1.000000  1.000000    0.185233  1.000000  3.181818   \n\n          necm25          cost     nofb20      nofc80  bias_train  \\\nmean    1.300757   3579.802868   2.763623   76.475075    0.065685   \nmedian  1.126795    974.000000   2.000000   54.000000    0.054417   \nmin     0.000000      0.000000   0.000000    1.000000    0.002347   \nmax     7.954545  56593.000000  35.000000  634.000000    0.333333   \n\n        bias_train_processed  bias_test  ratio_bias  ratio_bias_processed  \\\nmean                0.150173   0.065939    1.142955              0.726042   \nmedian              0.108252   0.054348    1.004008              0.496633   \nmin                 0.002347   0.002481    0.066808              0.023711   \nmax                 0.692641   0.382353   14.300000             14.300000   \n\n        prop1_defect  prop1_clean    num_train  num_train_processed  \\\nmean      152.347081    15.084337   506.490566           560.944302   \nmedian     83.400000    10.806122   425.000000           462.000000   \nmin         5.600000     1.819095   100.000000           100.000000   \nmax      3756.000000    92.700000  1708.000000          1940.000000   \n\n          num_test        diff  potential  \nmean    186.097717         NaN        NaN  \nmedian  153.000000  990.309524        NaN  \nmin      28.000000        -inf        NaN  \nmax     667.000000         inf        NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>configuration</th>\n      <th>release</th>\n      <th>recall</th>\n      <th>precision</th>\n      <th>fpr</th>\n      <th>f_measure</th>\n      <th>g_measure</th>\n      <th>balance</th>\n      <th>accuracy</th>\n      <th>error</th>\n      <th>error_type1</th>\n      <th>error_type2</th>\n      <th>mcc</th>\n      <th>consistency</th>\n      <th>auc</th>\n      <th>auc_alberg</th>\n      <th>auc_roi</th>\n      <th>necm10</th>\n      <th>necm25</th>\n      <th>cost</th>\n      <th>nofb20</th>\n      <th>nofc80</th>\n      <th>bias_train</th>\n      <th>bias_train_processed</th>\n      <th>bias_test</th>\n      <th>ratio_bias</th>\n      <th>ratio_bias_processed</th>\n      <th>prop1_defect</th>\n      <th>prop1_clean</th>\n      <th>num_train</th>\n      <th>num_train_processed</th>\n      <th>num_test</th>\n      <th>diff</th>\n      <th>potential</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>mean</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.171032</td>\n      <td>0.521851</td>\n      <td>0.022190</td>\n      <td>0.193396</td>\n      <td>0.239728</td>\n      <td>0.412477</td>\n      <td>0.928764</td>\n      <td>0.071236</td>\n      <td>0.326751</td>\n      <td>0.056615</td>\n      <td>0.182078</td>\n      <td>0.114417</td>\n      <td>0.790624</td>\n      <td>0.013403</td>\n      <td>0.575275</td>\n      <td>0.532306</td>\n      <td>1.300757</td>\n      <td>3579.802868</td>\n      <td>2.763623</td>\n      <td>76.475075</td>\n      <td>0.065685</td>\n      <td>0.150173</td>\n      <td>0.065939</td>\n      <td>1.142955</td>\n      <td>0.726042</td>\n      <td>152.347081</td>\n      <td>15.084337</td>\n      <td>506.490566</td>\n      <td>560.944302</td>\n      <td>186.097717</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>median</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.090909</td>\n      <td>0.500000</td>\n      <td>0.010989</td>\n      <td>0.142857</td>\n      <td>0.166604</td>\n      <td>0.357168</td>\n      <td>0.940594</td>\n      <td>0.059406</td>\n      <td>0.190476</td>\n      <td>0.047120</td>\n      <td>0.129023</td>\n      <td>0.015152</td>\n      <td>0.807238</td>\n      <td>0.006870</td>\n      <td>0.572759</td>\n      <td>0.461538</td>\n      <td>1.126795</td>\n      <td>974.000000</td>\n      <td>2.000000</td>\n      <td>54.000000</td>\n      <td>0.054417</td>\n      <td>0.108252</td>\n      <td>0.054348</td>\n      <td>1.004008</td>\n      <td>0.496633</td>\n      <td>83.400000</td>\n      <td>10.806122</td>\n      <td>425.000000</td>\n      <td>462.000000</td>\n      <td>153.000000</td>\n      <td>990.309524</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.270018</td>\n      <td>0.600000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-0.173902</td>\n      <td>-0.466667</td>\n      <td>0.055556</td>\n      <td>0.000000</td>\n      <td>0.012178</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.002347</td>\n      <td>0.002347</td>\n      <td>0.002481</td>\n      <td>0.066808</td>\n      <td>0.023711</td>\n      <td>5.600000</td>\n      <td>1.819095</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>28.000000</td>\n      <td>-inf</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.404762</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.400000</td>\n      <td>12.000000</td>\n      <td>0.476190</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.185233</td>\n      <td>1.000000</td>\n      <td>3.181818</td>\n      <td>7.954545</td>\n      <td>56593.000000</td>\n      <td>35.000000</td>\n      <td>634.000000</td>\n      <td>0.333333</td>\n      <td>0.692641</td>\n      <td>0.382353</td>\n      <td>14.300000</td>\n      <td>14.300000</td>\n      <td>3756.000000</td>\n      <td>92.700000</td>\n      <td>1708.000000</td>\n      <td>1940.000000</td>\n      <td>667.000000</td>\n      <td>inf</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt_df_converted = convert_dataframe(bt_df)\n",
    "few_descriptive_stats(bt_df_converted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Check for the completeness of bootstrap experiment data\n",
    "#### expected values:\n",
    "- number of releases = 265\n",
    "- instances per release = 200 (2*100)\n",
    "- total number of instances = 53000 (2*26500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of releases:        265\n",
      "Instances per release:     [200]\n",
      "Total number of instances: 53000\n",
      "\n",
      "Overall number of NaN:               12075\n",
      "Overall number of NaN (no 'diff'):   0\n",
      "Number of rows with NaN:             12075\n",
      "Number of rows with NaN (no 'diff'): 0\n",
      "\n",
      "NaNs per variable:\n",
      "diff    12075\n",
      "dtype: int64\n",
      "\n",
      "infs per variable:\n",
      "diff    12104\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "num_releases = bt_df_converted[\"release\"].nunique()\n",
    "instances_per_release = bt_df_converted[\"num_test\"].groupby(bt_df_converted[\"release\"]).count().unique().tolist()\n",
    "print(f\"Number of releases:        {num_releases}\")\n",
    "print(f\"Instances per release:     {instances_per_release}\")\n",
    "print(f\"Total number of instances: {bt_df_converted.shape[0]}\\n\")\n",
    "nan_and_inf_evaluation(bt_df_converted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save converted bootstrap experiment dataframe to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_df_converted.to_csv(CSV_OUTPUT_BOOTSTRAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get generalization experiment data\n",
    "### Query generalization experiment dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of dataframe: (1698, 115)\n"
     ]
    },
    {
     "data": {
      "text/plain": "        configuration  release  idresults  configurationName  productName  \\\nmean              NaN      NaN    78909.5                NaN          NaN   \nmedian            NaN      NaN    78909.5                NaN          NaN   \nmin               NaN      NaN    78061.0                NaN          NaN   \nmax               NaN      NaN    79758.0                NaN          NaN   \n\n        classifier     testsize      trainsize  trainsizeOriginal  biasTest  \\\nmean           NaN   486.586572   25254.421673       25262.964664  0.064404   \nmedian         NaN   403.500000    6557.000000        6557.000000  0.052397   \nmin            NaN    29.000000      81.000000         100.000000  0.000000   \nmax            NaN  1708.000000  128751.000000      128751.000000  0.285714   \n\n        biasTraining  biasTrainingOriginal  prop1Defect  prop1Clean     error  \\\nmean        0.047983              0.048029    92.169938   14.794172  0.257466   \nmedian      0.052895              0.052907    53.043810   10.487179  0.180602   \nmin         0.000000              0.005025    -1.000000    2.542857  0.001441   \nmax         0.126394              0.126394  1184.000000   50.171569  0.990411   \n\n          recall  precision    fscore    gscore       mcc  ...  \\\nmean    0.459338   0.172051  0.152568  0.404748  0.080306  ...   \nmedian  0.500000   0.133631  0.186141  0.504011  0.155656  ...   \nmin    -1.000000  -1.000000 -1.000000 -1.000000 -1.000000  ...   \nmax     1.000000   1.000000  0.727273  0.975207  0.714851  ...   \n\n        lowerConstNtoMImp40  upperConstNtoMImp40  lowerSize1to1Imp40  \\\nmean              24.941260         2.361026e+04         5003.268281   \nmedian            10.488240         4.919852e+01         3076.303419   \nmin               -1.000000        -1.000000e+00           -1.000000   \nmax             1805.555556         2.089321e+07        90085.000000   \n\n        upperSize1to1Imp40  lowerSize1toMImp40  upperSize1toMImp40  \\\nmean           4867.556762         4149.515320         4447.226029   \nmedian         2464.542824         2336.944444         2254.625000   \nmin              -1.000000           -1.000000           -1.000000   \nmax          122528.333333        90085.000000       122528.333333   \n\n        lowerSizeNtoMImp40  upperSizeNtoMImp40  lowerConst1to1Imp50  \\\nmean           5888.258576        1.340923e+06            23.318783   \nmedian         3381.834638        3.441435e+03            12.000000   \nmin              -1.000000       -1.000000e+00            -1.000000   \nmax          262345.679012        1.218560e+09           786.000000   \n\n        upperConst1to1Imp50  lowerConst1toMImp50  upperConst1toMImp50  \\\nmean              91.158914            20.267218            84.051431   \nmedian            42.119298             9.376518            36.829167   \nmin               -1.000000            -1.000000            -1.000000   \nmax             1612.000000           786.000000          1612.000000   \n\n        lowerConstNtoMImp50  upperConstNtoMImp50  lowerSize1to1Imp50  \\\nmean              32.157967         1.867605e+06         6003.939369   \nmedian            12.695798         6.090598e+01         3691.564103   \nmin               -1.000000        -1.000000e+00           -1.000000   \nmax             3744.000000         1.660944e+09       108102.000000   \n\n        upperSize1to1Imp50  lowerSize1toMImp50  upperSize1toMImp50  \\\nmean           5841.102861         4979.435817         5336.695616   \nmedian         2957.451389         2804.333333         2705.550000   \nmin              -1.000000           -1.000000           -1.000000   \nmax          147034.000000       108102.000000       147034.000000   \n\n        lowerSizeNtoMImp50  upperSizeNtoMImp50  \nmean           7433.763590        1.060386e+08  \nmedian         4109.079365        4.259188e+03  \nmin              -1.000000       -1.000000e+00  \nmax          544000.000000        9.687165e+10  \n\n[4 rows x 117 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>configuration</th>\n      <th>release</th>\n      <th>idresults</th>\n      <th>configurationName</th>\n      <th>productName</th>\n      <th>classifier</th>\n      <th>testsize</th>\n      <th>trainsize</th>\n      <th>trainsizeOriginal</th>\n      <th>biasTest</th>\n      <th>biasTraining</th>\n      <th>biasTrainingOriginal</th>\n      <th>prop1Defect</th>\n      <th>prop1Clean</th>\n      <th>error</th>\n      <th>recall</th>\n      <th>precision</th>\n      <th>fscore</th>\n      <th>gscore</th>\n      <th>mcc</th>\n      <th>...</th>\n      <th>lowerConstNtoMImp40</th>\n      <th>upperConstNtoMImp40</th>\n      <th>lowerSize1to1Imp40</th>\n      <th>upperSize1to1Imp40</th>\n      <th>lowerSize1toMImp40</th>\n      <th>upperSize1toMImp40</th>\n      <th>lowerSizeNtoMImp40</th>\n      <th>upperSizeNtoMImp40</th>\n      <th>lowerConst1to1Imp50</th>\n      <th>upperConst1to1Imp50</th>\n      <th>lowerConst1toMImp50</th>\n      <th>upperConst1toMImp50</th>\n      <th>lowerConstNtoMImp50</th>\n      <th>upperConstNtoMImp50</th>\n      <th>lowerSize1to1Imp50</th>\n      <th>upperSize1to1Imp50</th>\n      <th>lowerSize1toMImp50</th>\n      <th>upperSize1toMImp50</th>\n      <th>lowerSizeNtoMImp50</th>\n      <th>upperSizeNtoMImp50</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>mean</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>78909.5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>486.586572</td>\n      <td>25254.421673</td>\n      <td>25262.964664</td>\n      <td>0.064404</td>\n      <td>0.047983</td>\n      <td>0.048029</td>\n      <td>92.169938</td>\n      <td>14.794172</td>\n      <td>0.257466</td>\n      <td>0.459338</td>\n      <td>0.172051</td>\n      <td>0.152568</td>\n      <td>0.404748</td>\n      <td>0.080306</td>\n      <td>...</td>\n      <td>24.941260</td>\n      <td>2.361026e+04</td>\n      <td>5003.268281</td>\n      <td>4867.556762</td>\n      <td>4149.515320</td>\n      <td>4447.226029</td>\n      <td>5888.258576</td>\n      <td>1.340923e+06</td>\n      <td>23.318783</td>\n      <td>91.158914</td>\n      <td>20.267218</td>\n      <td>84.051431</td>\n      <td>32.157967</td>\n      <td>1.867605e+06</td>\n      <td>6003.939369</td>\n      <td>5841.102861</td>\n      <td>4979.435817</td>\n      <td>5336.695616</td>\n      <td>7433.763590</td>\n      <td>1.060386e+08</td>\n    </tr>\n    <tr>\n      <th>median</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>78909.5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>403.500000</td>\n      <td>6557.000000</td>\n      <td>6557.000000</td>\n      <td>0.052397</td>\n      <td>0.052895</td>\n      <td>0.052907</td>\n      <td>53.043810</td>\n      <td>10.487179</td>\n      <td>0.180602</td>\n      <td>0.500000</td>\n      <td>0.133631</td>\n      <td>0.186141</td>\n      <td>0.504011</td>\n      <td>0.155656</td>\n      <td>...</td>\n      <td>10.488240</td>\n      <td>4.919852e+01</td>\n      <td>3076.303419</td>\n      <td>2464.542824</td>\n      <td>2336.944444</td>\n      <td>2254.625000</td>\n      <td>3381.834638</td>\n      <td>3.441435e+03</td>\n      <td>12.000000</td>\n      <td>42.119298</td>\n      <td>9.376518</td>\n      <td>36.829167</td>\n      <td>12.695798</td>\n      <td>6.090598e+01</td>\n      <td>3691.564103</td>\n      <td>2957.451389</td>\n      <td>2804.333333</td>\n      <td>2705.550000</td>\n      <td>4109.079365</td>\n      <td>4.259188e+03</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>78061.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>29.000000</td>\n      <td>81.000000</td>\n      <td>100.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.005025</td>\n      <td>-1.000000</td>\n      <td>2.542857</td>\n      <td>0.001441</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>...</td>\n      <td>-1.000000</td>\n      <td>-1.000000e+00</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000e+00</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000e+00</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000e+00</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>79758.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1708.000000</td>\n      <td>128751.000000</td>\n      <td>128751.000000</td>\n      <td>0.285714</td>\n      <td>0.126394</td>\n      <td>0.126394</td>\n      <td>1184.000000</td>\n      <td>50.171569</td>\n      <td>0.990411</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.727273</td>\n      <td>0.975207</td>\n      <td>0.714851</td>\n      <td>...</td>\n      <td>1805.555556</td>\n      <td>2.089321e+07</td>\n      <td>90085.000000</td>\n      <td>122528.333333</td>\n      <td>90085.000000</td>\n      <td>122528.333333</td>\n      <td>262345.679012</td>\n      <td>1.218560e+09</td>\n      <td>786.000000</td>\n      <td>1612.000000</td>\n      <td>786.000000</td>\n      <td>1612.000000</td>\n      <td>3744.000000</td>\n      <td>1.660944e+09</td>\n      <td>108102.000000</td>\n      <td>147034.000000</td>\n      <td>108102.000000</td>\n      <td>147034.000000</td>\n      <td>544000.000000</td>\n      <td>9.687165e+10</td>\n    </tr>\n  </tbody>\n</table>\n<p>4 rows × 117 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if USE_DATABASE:\n",
    "    db_table = SQL_TABLENAME_GENERALIZATION\n",
    "    real_df = pd.read_sql_query(f\"SELECT * FROM {db_table} WHERE configurationName NOT LIKE '%NoSmote%' AND configurationName NOT LIKE '%Smotuned%'\", dbcon)\n",
    "    real_df.to_csv(CSV_CROSSPARE_GENERALIZATION, index=False)\n",
    "else:\n",
    "    real_df = pd.read_csv(CSV_CROSSPARE_GENERALIZATION,index_col=False)\n",
    "\n",
    "print(f\"shape of dataframe: {real_df.shape}\")\n",
    "\n",
    "release_col = real_df[\"productName\"].str.replace(\"_aggregated.csv\", \"\", regex=True)\n",
    "real_df.insert(0, 'release', release_col)\n",
    "\n",
    "config_col = real_df['configurationName'].str.replace(\"MYNBOU_\", \"\", regex=True)\n",
    "real_df.insert(0, 'configuration', config_col)\n",
    "\n",
    "few_descriptive_stats(real_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Convert bootstrap dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        configuration  release    recall  precision       fpr  f_measure  \\\nmean              NaN      NaN  0.544143   0.180296  0.268267   0.199093   \nmedian            NaN      NaN  0.538462   0.135129  0.156124   0.186141   \nmin               NaN      NaN  0.000000   0.000000  0.000000   0.000000   \nmax               NaN      NaN  1.000000   1.000000  1.000000   0.727273   \n\n        g_measure   balance  accuracy     error  error_type1  error_type2  \\\nmean     0.479825  0.548689  0.715989  0.257466          inf     0.034347   \nmedian   0.528660  0.549462  0.819398  0.180602     2.857143     0.021529   \nmin      0.000000  0.134187  0.000000  0.001441     0.000000     0.000000   \nmax      0.999279  0.998981  0.998559  0.990411          inf     0.254545   \n\n             mcc  consistency       auc  auc_alberg   auc_roi    necm10  \\\nmean    0.159812     0.537867  0.713829    0.006730  0.526263  0.534241   \nmedian  0.155656     0.483689  0.741370    0.001469  0.528006  0.488062   \nmin    -0.365541    -0.247191  0.017964    0.000000  0.095069  0.001441   \nmax     0.714851     4.235294  1.000000    0.095691  1.000000  2.004505   \n\n          necm25           cost     nofb20       nofc80  bias_train  \\\nmean    0.995533   32011.067138   5.942874   257.845633    0.048029   \nmedian  0.782382   15260.000000   4.000000   180.000000    0.052907   \nmin     0.001441       0.000000   0.000000     1.000000    0.005025   \nmax     4.977477  187780.000000  83.000000  1630.000000    0.126394   \n\n        bias_train_processed  bias_test  ratio_bias  ratio_bias_processed  \\\nmean                0.047983   0.064404    1.726356              1.726287   \nmedian              0.052895   0.052397    1.243741              1.237294   \nmin                 0.000000   0.000000    0.000000              0.000000   \nmax                 0.126394   0.285714   17.424007             18.949020   \n\n        prop1_defect  prop1_clean      num_train  num_train_processed  \\\nmean       96.295544    14.794172   25262.964664         25254.421673   \nmedian     55.652778    10.487179    6557.000000          6557.000000   \nmin         5.678571     2.542857     100.000000            81.000000   \nmax      1184.000000    50.171569  128751.000000        128751.000000   \n\n           num_test       diff  potential  \nmean     486.586572        NaN        NaN  \nmedian   403.500000  78.004924        NaN  \nmin       29.000000       -inf        NaN  \nmax     1708.000000        inf        NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>configuration</th>\n      <th>release</th>\n      <th>recall</th>\n      <th>precision</th>\n      <th>fpr</th>\n      <th>f_measure</th>\n      <th>g_measure</th>\n      <th>balance</th>\n      <th>accuracy</th>\n      <th>error</th>\n      <th>error_type1</th>\n      <th>error_type2</th>\n      <th>mcc</th>\n      <th>consistency</th>\n      <th>auc</th>\n      <th>auc_alberg</th>\n      <th>auc_roi</th>\n      <th>necm10</th>\n      <th>necm25</th>\n      <th>cost</th>\n      <th>nofb20</th>\n      <th>nofc80</th>\n      <th>bias_train</th>\n      <th>bias_train_processed</th>\n      <th>bias_test</th>\n      <th>ratio_bias</th>\n      <th>ratio_bias_processed</th>\n      <th>prop1_defect</th>\n      <th>prop1_clean</th>\n      <th>num_train</th>\n      <th>num_train_processed</th>\n      <th>num_test</th>\n      <th>diff</th>\n      <th>potential</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>mean</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.544143</td>\n      <td>0.180296</td>\n      <td>0.268267</td>\n      <td>0.199093</td>\n      <td>0.479825</td>\n      <td>0.548689</td>\n      <td>0.715989</td>\n      <td>0.257466</td>\n      <td>inf</td>\n      <td>0.034347</td>\n      <td>0.159812</td>\n      <td>0.537867</td>\n      <td>0.713829</td>\n      <td>0.006730</td>\n      <td>0.526263</td>\n      <td>0.534241</td>\n      <td>0.995533</td>\n      <td>32011.067138</td>\n      <td>5.942874</td>\n      <td>257.845633</td>\n      <td>0.048029</td>\n      <td>0.047983</td>\n      <td>0.064404</td>\n      <td>1.726356</td>\n      <td>1.726287</td>\n      <td>96.295544</td>\n      <td>14.794172</td>\n      <td>25262.964664</td>\n      <td>25254.421673</td>\n      <td>486.586572</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>median</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.538462</td>\n      <td>0.135129</td>\n      <td>0.156124</td>\n      <td>0.186141</td>\n      <td>0.528660</td>\n      <td>0.549462</td>\n      <td>0.819398</td>\n      <td>0.180602</td>\n      <td>2.857143</td>\n      <td>0.021529</td>\n      <td>0.155656</td>\n      <td>0.483689</td>\n      <td>0.741370</td>\n      <td>0.001469</td>\n      <td>0.528006</td>\n      <td>0.488062</td>\n      <td>0.782382</td>\n      <td>15260.000000</td>\n      <td>4.000000</td>\n      <td>180.000000</td>\n      <td>0.052907</td>\n      <td>0.052895</td>\n      <td>0.052397</td>\n      <td>1.243741</td>\n      <td>1.237294</td>\n      <td>55.652778</td>\n      <td>10.487179</td>\n      <td>6557.000000</td>\n      <td>6557.000000</td>\n      <td>403.500000</td>\n      <td>78.004924</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.134187</td>\n      <td>0.000000</td>\n      <td>0.001441</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-0.365541</td>\n      <td>-0.247191</td>\n      <td>0.017964</td>\n      <td>0.000000</td>\n      <td>0.095069</td>\n      <td>0.001441</td>\n      <td>0.001441</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.005025</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.678571</td>\n      <td>2.542857</td>\n      <td>100.000000</td>\n      <td>81.000000</td>\n      <td>29.000000</td>\n      <td>-inf</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.727273</td>\n      <td>0.999279</td>\n      <td>0.998981</td>\n      <td>0.998559</td>\n      <td>0.990411</td>\n      <td>inf</td>\n      <td>0.254545</td>\n      <td>0.714851</td>\n      <td>4.235294</td>\n      <td>1.000000</td>\n      <td>0.095691</td>\n      <td>1.000000</td>\n      <td>2.004505</td>\n      <td>4.977477</td>\n      <td>187780.000000</td>\n      <td>83.000000</td>\n      <td>1630.000000</td>\n      <td>0.126394</td>\n      <td>0.126394</td>\n      <td>0.285714</td>\n      <td>17.424007</td>\n      <td>18.949020</td>\n      <td>1184.000000</td>\n      <td>50.171569</td>\n      <td>128751.000000</td>\n      <td>128751.000000</td>\n      <td>1708.000000</td>\n      <td>inf</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_df_converted = convert_dataframe(real_df)\n",
    "few_descriptive_stats(real_df_converted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Check for the completeness of generalization experiment data\n",
    "#### expected values:\n",
    "- number of releases = 398\n",
    "- instances per release = 0-6\n",
    "- maximal total number of instances = 6*398 = 2388"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of releases:        337\n",
      "Instances per release:     [3, 6]\n",
      "Total number of instances: 1698\n",
      "\n",
      "Overall number of NaN:               512\n",
      "Overall number of NaN (no 'diff'):   434\n",
      "Number of rows with NaN:             79\n",
      "Number of rows with NaN (no 'diff'): 74\n",
      "\n",
      "NaNs per variable:\n",
      "consistency             72\n",
      "auc                     72\n",
      "auc_alberg              72\n",
      "auc_roi                 72\n",
      "nofc80                  72\n",
      "ratio_bias_processed     2\n",
      "prop1_defect            72\n",
      "diff                    78\n",
      "dtype: int64\n",
      "\n",
      "infs per variable:\n",
      "error_type1     72\n",
      "diff           236\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "num_releases = real_df_converted[\"release\"].nunique()\n",
    "instances_per_release = real_df_converted[\"num_test\"].groupby(real_df_converted[\"release\"]).count().unique().tolist()\n",
    "print(f\"Number of releases:        {num_releases}\")\n",
    "print(f\"Instances per release:     {instances_per_release}\")\n",
    "print(f\"Total number of instances: {real_df_converted.shape[0]}\\n\")\n",
    "nan_and_inf_evaluation(real_df_converted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save converted generalization experiment dataframe to csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "real_df_converted.to_csv(CSV_OUTPUT_GENERALIZATION)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}